{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Build-Vocabulary\" data-toc-modified-id=\"Build-Vocabulary-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Build Vocabulary</a></span></li><li><span><a href=\"#Unigram-spell-checker\" data-toc-modified-id=\"Unigram-spell-checker-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Unigram spell checker</a></span><ul class=\"toc-item\"><li><span><a href=\"#Evaluate-accuracy\" data-toc-modified-id=\"Evaluate-accuracy-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Evaluate accuracy</a></span></li></ul></li><li><span><a href=\"#Bigram-spell-checker\" data-toc-modified-id=\"Bigram-spell-checker-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Bigram spell checker</a></span><ul class=\"toc-item\"><li><span><a href=\"#Evaluating\" data-toc-modified-id=\"Evaluating-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Evaluating</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T13:22:55.609493Z",
     "start_time": "2021-04-23T13:22:55.587124Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T13:42:35.974797Z",
     "start_time": "2021-04-23T13:42:35.955281Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections.abc import Iterable\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "import os,sys,inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir) \n",
    "\n",
    "import data\n",
    "from data import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T13:42:36.484967Z",
     "start_time": "2021-04-23T13:42:36.337107Z"
    }
   },
   "outputs": [],
   "source": [
    "train, test = utils.get_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T13:42:36.589536Z",
     "start_time": "2021-04-23T13:42:36.569550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original': ['they', 'can', 'go', 'quite', 'farst'],\n",
       " 'corrected': ['they', 'can', 'go', 'quite', 'fast'],\n",
       " 'indexes': [4]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T13:42:36.780419Z",
     "start_time": "2021-04-23T13:42:36.759640Z"
    }
   },
   "outputs": [],
   "source": [
    "X_tr = [x['original'] for x in train]\n",
    "y_tr = [x['corrected'] for x in train]\n",
    "y_tr_idx =  [x['indexes'] for x in train]\n",
    "\n",
    "X_te = [x['original'] for x in test]\n",
    "y_te = [x['corrected'] for x in test]\n",
    "y_te_idx =  [x['indexes'] for x in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T13:42:37.042539Z",
     "start_time": "2021-04-23T13:42:36.958439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocabulary)=|3451\n"
     ]
    }
   ],
   "source": [
    "from nltk.collocations import BigramCollocationFinder\n",
    "\n",
    "\n",
    "bigram_finder = BigramCollocationFinder.from_documents(X_tr)\n",
    "bigram_freq_dict = dict(bigram_finder.ngram_fd.items())\n",
    "list(bigram_freq_dict.keys())[0:10]\n",
    "\n",
    "import itertools\n",
    "vocabulary = set(list(itertools.chain(*bigram_freq_dict.keys())))\n",
    "print(f'len(vocabulary)=|{len(vocabulary)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T13:42:37.157745Z",
     "start_time": "2021-04-23T13:42:37.136472Z"
    }
   },
   "outputs": [],
   "source": [
    "bigram_freq_dict = dict(bigram_finder.ngram_fd.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T13:42:37.528196Z",
     "start_time": "2021-04-23T13:42:37.509445Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.collocations import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T13:42:37.724469Z",
     "start_time": "2021-04-23T13:42:37.703963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'man', 'went'), ('man', 'went', 'to'), ('went', 'to', 'the')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in nltk.collocations.ngrams(['the','man','went','to','the'],n=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T13:42:38.430755Z",
     "start_time": "2021-04-23T13:42:38.407408Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "corrected_sentences = [train[n]['corrected'] for n in range(len(train))]\n",
    "corrected_words = [word.lower() for sentence in corrected_sentences for word in sentence]\n",
    "unique_corrected_words = set(corrected_words)\n",
    "n_total_words = len(corrected_words)\n",
    "vocabulary = unique_corrected_words\n",
    "\n",
    "def build_unigrams(corrected_words):\n",
    "    return Counter(corrected_words) \n",
    "\n",
    "def prob(word, unigrams, n_total_words):\n",
    "    word = word.lower()\n",
    "    word_counts = unigrams[word]\n",
    "    return word_counts / n_total_words\n",
    "\n",
    "# Test your code with the following\n",
    "# assert(unigram(\"me\")==87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T13:42:39.360141Z",
     "start_time": "2021-04-23T13:42:39.340404Z"
    }
   },
   "outputs": [],
   "source": [
    "unigrams = build_unigrams(corrected_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T13:42:39.869721Z",
     "start_time": "2021-04-23T13:42:39.849798Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002200926223118896\n",
      "0.003989178779402999\n",
      "0.00018341051859324133\n"
     ]
    }
   ],
   "source": [
    "print(prob('house', unigrams, n_total_words))\n",
    "print(prob('me', unigrams, n_total_words))\n",
    "print(prob('television', unigrams, n_total_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T13:42:40.095248Z",
     "start_time": "2021-04-23T13:42:40.075279Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 87, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigrams['house'], unigrams['me'], unigrams['television']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T13:42:41.136795Z",
     "start_time": "2021-04-23T13:42:41.117921Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T13:43:49.417776Z",
     "start_time": "2021-04-23T13:43:49.398141Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_candidates(token, vocabulary):\n",
    "    # Write your code here.\n",
    "    distance_token_to_words = {word:edit_distance(word,token.lower()) for word in vocabulary}\n",
    "    minimum_distance = min(distance_token_to_words.values())\n",
    "    return sorted([word for word, distance in distance_token_to_words.items() \n",
    "                   if distance <= minimum_distance], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T13:43:49.776028Z",
     "start_time": "2021-04-23T13:43:49.757145Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test your code as follows\n",
    "#assert get_candidates(\"minde\",vocabulary) == ['mine', 'mind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T13:43:50.043605Z",
     "start_time": "2021-04-23T13:43:49.982139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boss', 'box', 'boys']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_candidates(\"boxs\",vocabulary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T13:41:38.321716Z",
     "start_time": "2021-04-22T13:41:35.495079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.6 ms ± 270 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit get_candidates(\"min\",vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigram spell checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T13:41:39.792882Z",
     "start_time": "2021-04-22T13:41:39.789961Z"
    }
   },
   "outputs": [],
   "source": [
    "def correct_tokens(tokenized_sentence, unigrams, n_total_words):\n",
    "    tokenized_sentence = tokenized_sentence.copy()\n",
    "    \n",
    "    for index,word in enumerate(tokenized_sentence):\n",
    "        if (word and word.lower()) not in unique_corrected_words:\n",
    "            candidates = {candidate:prob(candidate, unigrams, n_total_words) for candidate in get_candidates(word,vocabulary)}\n",
    "            best_candidate  = max(candidates, key=candidates.get)\n",
    "            tokenized_sentence[index] = best_candidate\n",
    "\n",
    "    return tokenized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T13:41:40.071568Z",
     "start_time": "2021-04-22T13:41:40.014980Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'white', 'cat']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_tokens(tokenized_sentence = [\"this\", \"whitr\", \"cat\"],  \n",
    "               unigrams=unigrams, \n",
    "               n_total_words=n_total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T13:41:40.949834Z",
     "start_time": "2021-04-22T13:41:40.903374Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'my', 'cat']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_tokens(tokenized_sentence = [\"this\",\"is\",\"my\",\"caat\"],  \n",
    "               unigrams=unigrams, \n",
    "               n_total_words=n_total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T13:41:41.158171Z",
     "start_time": "2021-04-22T13:41:41.102011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Joan', 'likes', 'pigs', 'and', 'cats']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_tokens(tokenized_sentence = [\"Joan\",\"likes\",\"pissa\",\"and\",\"cats\"],  \n",
    "               unigrams=unigrams, \n",
    "               n_total_words=n_total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T13:41:42.043196Z",
     "start_time": "2021-04-22T13:41:42.040165Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'pizza' in vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T10:07:46.165989Z",
     "start_time": "2021-04-16T10:07:46.147178Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(test,  unigrams, n_total_words):\n",
    "    # Write your code here\n",
    "    count_total_words = 0\n",
    "    count_corrected_words = 0\n",
    "    for sentence in test:\n",
    "        corrected_sentence = correct_tokens(sentence['original'], unigrams, n_total_words)  \n",
    "        count_total_words +=len(sentence['corrected'])\n",
    "        count_corrected_words += sum(corrected_sentence[n] == sentence['corrected'][n] \n",
    "                                     for n in range(len(sentence['corrected'])))\n",
    "    return count_corrected_words/count_total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T10:07:56.201531Z",
     "start_time": "2021-04-16T10:07:46.563698Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8380281690140845"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(test, unigrams, n_total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigram spell checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T10:08:16.461754Z",
     "start_time": "2021-04-16T10:08:16.410003Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics.distance import edit_distance\n",
    "from collections import Counter\n",
    "\n",
    "corrected_sentences = [train[n]['corrected'] for n in range(len(train))]\n",
    "corrected_words = [word.lower() for sentence in corrected_sentences for word in sentence]\n",
    "unique_corrected_words = set(corrected_words)\n",
    "finder = BigramCollocationFinder.from_words(corrected_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T10:08:17.160524Z",
     "start_time": "2021-04-16T10:08:17.141192Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['they', 'can', 'go', 'quite', 'fast', 'this', 'was', 'a', 'royal', 'enfield']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T10:08:20.807410Z",
     "start_time": "2021-04-16T10:08:20.786467Z"
    }
   },
   "outputs": [],
   "source": [
    "unigram_freq_dict = build_unigrams(corrected_words)\n",
    "bigram_freq_dict  = dict(finder.ngram_fd.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T10:08:23.797604Z",
     "start_time": "2021-04-16T10:08:23.778754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['they', 'can', 'go', 'quite', 'fast', 'this', 'was', 'a', 'royal', 'enfield']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T16:03:32.849824Z",
     "start_time": "2021-04-22T16:03:32.844421Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('they', 'can'), 4),\n",
       " (('can', 'go'), 4),\n",
       " (('go', 'quite'), 1),\n",
       " (('quite', 'farst'), 1),\n",
       " (('this', 'was'), 3),\n",
       " (('was', 'a'), 34),\n",
       " (('a', 'Royl'), 3),\n",
       " (('Royl', 'Enfield'), 5),\n",
       " (('Enfield', 'Consulatoin'), 1),\n",
       " (('Consulatoin', '?'), 1)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools \n",
    "def top_k_dict(d, top_k = 10):\n",
    "    return [(x,bigram_freq_dict[x]) for k,x in enumerate(bigram_freq_dict) if k<top_k]\n",
    "\n",
    "top_k_dict(bigram_freq_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can notice that actually the bigrams where not computed correctly because we concatenated all the data from the  corrected sentences into a single list `corrected_words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T16:03:33.365105Z",
     "start_time": "2021-04-22T16:03:33.361297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original': ['they', 'can', 'go', 'quite', 'farst'],\n",
       " 'corrected': ['they', 'can', 'go', 'quite', 'fast'],\n",
       " 'indexes': [4]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T16:03:33.566602Z",
     "start_time": "2021-04-22T16:03:33.563133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original': ['this', 'was', 'a', 'Royl', 'Enfield', 'Consulatoin', '?', '_'],\n",
       " 'corrected': ['this', 'was', 'a', 'Royal', 'Enfield', '_', '?', '_'],\n",
       " 'indexes': [3, 5]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see how the bigram `(fast,this)` appears in the `bigram_freq_dict` but in reality this might not even be in the training data.\n",
    "\n",
    "It is a consequence of concatenating the training dat into a single line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T16:03:33.998066Z",
     "start_time": "2021-04-22T16:03:33.994242Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('they', 'can'),\n",
       " ('can', 'go'),\n",
       " ('go', 'quite'),\n",
       " ('quite', 'farst'),\n",
       " ('this', 'was'),\n",
       " ('was', 'a')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bigram_freq_dict)[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we could build the bigrams avoiding this issue using `BigramCollocationFinder.from_documents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T16:03:34.444858Z",
     "start_time": "2021-04-22T16:03:34.440979Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(('they', 'can'), 1), (('can', 'go'), 1), (('go', 'quite'), 1), (('quite', 'fast'), 1), (('this', 'was'), 1), (('was', 'a'), 1), (('a', 'Royal'), 1), (('Royal', 'Enfield'), 1), (('Enfield', '_'), 1), (('_', '?'), 1), (('?', '_'), 1)])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_finder = BigramCollocationFinder.from_documents([['they', 'can', 'go', 'quite', 'fast'],\n",
    "                                                         ['this', 'was', 'a', 'Royal', 'Enfield', '_', '?', '_']])\n",
    "bigram_freq_dict_aux = bigram_finder.ngram_fd.items()\n",
    "bigram_freq_dict_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us build again `bigram_freq_dict_aux` using all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T16:03:39.289972Z",
     "start_time": "2021-04-22T16:03:39.256197Z"
    }
   },
   "outputs": [],
   "source": [
    "corrected_sentences = [train[n]['corrected'] for n in range(len(train))]\n",
    "finder = BigramCollocationFinder.from_documents(corrected_sentences)\n",
    "bigram_freq_dict = dict(finder.ngram_fd.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T16:03:40.248460Z",
     "start_time": "2021-04-22T16:03:40.245825Z"
    }
   },
   "outputs": [],
   "source": [
    "def prob_word(word, word_to_count, n_total_words, n_vocabulary):\n",
    "    # Write your code here.\n",
    "    word = word.lower()\n",
    "    word_counts = word_to_count[word]\n",
    "    return word_counts / n_total_words\n",
    "\n",
    "#def prob_word(word, word_to_count, n_total_words, n_vocabulary): \n",
    "#    return (word_to_count[word]+1) / (n_total_words+ n_vocabulary)\n",
    "\n",
    "def bigrams_starting_by(word, bigram_freq_dictionary): \n",
    "    return [t for t in list(bigram_freq_dict.keys()) if t[0] == word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T16:03:40.518497Z",
     "start_time": "2021-04-22T16:03:40.516383Z"
    }
   },
   "outputs": [],
   "source": [
    "n_total_words, len(unique_corrected_words)\n",
    "n_vocabulary = len(unique_corrected_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T16:03:41.431569Z",
     "start_time": "2021-04-22T16:03:41.427241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dog', 'see'),\n",
       " ('dog', 'and'),\n",
       " ('dog', 'run'),\n",
       " ('dog', 'is'),\n",
       " ('dog', ','),\n",
       " ('dog', 'had'),\n",
       " ('dog', 'for'),\n",
       " ('dog', 'Toby'),\n",
       " ('dog', '.'),\n",
       " ('dog', 'it')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_starting_by('dog', bigram_freq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T16:03:41.958640Z",
     "start_time": "2021-04-22T16:03:41.955964Z"
    }
   },
   "outputs": [],
   "source": [
    "def return_dictionary_value(bigram, bigram_freq_dict):\n",
    "    try:\n",
    "        return bigram_freq_dict[bigram]\n",
    "    except KeyError:\n",
    "        return 0\n",
    "\n",
    "def count_bigrams(list_bigrams, bigram_freq_dict): \n",
    "    return sum([return_dictionary_value(bigram, bigram_freq_dict) for bigram in list_bigrams])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T16:42:08.475097Z",
     "start_time": "2021-04-22T16:42:08.472290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_bigrams([('they','can')], bigram_freq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T16:45:12.452805Z",
     "start_time": "2021-04-22T16:45:12.450361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13054"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bigram_freq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T16:42:10.004696Z",
     "start_time": "2021-04-22T16:42:10.002384Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def probability_bigram(word1, word2, bigram_freq_dict):\n",
    "    if count_bigrams([(word1,word2)], bigram_freq_dict) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return count_bigrams([(word1,word2)], bigram_freq_dict)/count_bigrams(bigrams_starting_by(word1,bigram_freq_dict), bigram_freq_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T16:42:10.444741Z",
     "start_time": "2021-04-22T16:42:10.440964Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09090909090909091"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word1, word2  = ('dog','is')\n",
    "probability_bigram(word1,word2, bigram_freq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T16:42:11.007228Z",
     "start_time": "2021-04-22T16:42:11.003592Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12686567164179105"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word1, word2  = ('was','a')\n",
    "probability_bigram(word1,word2, bigram_freq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T16:42:11.591469Z",
     "start_time": "2021-04-22T16:42:11.588759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word1, word2  = ('was','cat')\n",
    "probability_bigram(word1, word2, bigram_freq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T16:42:12.344442Z",
     "start_time": "2021-04-22T16:42:12.342212Z"
    }
   },
   "outputs": [],
   "source": [
    "def interpolation_probability(word1, word2, bigram_freq_dict, n_vocabulary, lambda_1 = 0.3): \n",
    "    return (1-lambda_1)*probability_bigram(word1, word2, bigram_freq_dict) +\\\n",
    "            lambda_1*prob_word(word2, unigrams, n_total_words, n_vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T16:03:47.034120Z",
     "start_time": "2021-04-22T16:03:47.030078Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09686619623303266"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word1, word2  = ('was','a')\n",
    "interpolation_probability(word1, word2, bigram_freq_dict, n_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T16:03:47.888220Z",
     "start_time": "2021-04-22T16:03:47.885084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00020633683341739648"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word1, word2  = ('was','cat')\n",
    "interpolation_probability(word1, word2, bigram_freq_dict, n_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T16:03:50.700473Z",
     "start_time": "2021-04-22T16:03:50.697900Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_candidates(token, vocabulary, max_dist):\n",
    "    distance_token_to_words = {word:edit_distance(word,token.lower()) for word in vocabulary}\n",
    "    minimum_distance = min(distance_token_to_words.values())\n",
    "    if minimum_distance < max_dist:\n",
    "        return sorted([word for word, distance in distance_token_to_words.items() if distance == minimum_distance])\n",
    "    return [token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T16:03:51.751081Z",
     "start_time": "2021-04-22T16:03:51.687537Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['house', 'huge', 'hus', 'use']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_candidates('huse', vocabulary, max_dist=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T16:03:53.788186Z",
     "start_time": "2021-04-22T16:03:53.712985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['witch']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_candidates('kitch', vocabulary, max_dist=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T16:03:55.177273Z",
     "start_time": "2021-04-22T16:03:55.175508Z"
    }
   },
   "outputs": [],
   "source": [
    "#%timeit get_candidates('hose', vocabulary, max_dist=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T16:03:55.428453Z",
     "start_time": "2021-04-22T16:03:55.424964Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def correct_with_bigrams(sentence, vocabulary):\n",
    "    for index,word in enumerate(sentence):\n",
    "        if ((word and word.lower()) not in vocabulary) and (not word[0].isupper()):\n",
    "            if index == 0: \n",
    "                previous_word = '.'\n",
    "            else:\n",
    "                previous_word = sentence[index-1].lower()\n",
    "            candidates = {candidate:interpolation_probability(previous_word, candidate, bigram_freq_dict,\n",
    "                                                              n_vocabulary, lambda_1=0.3) for candidate in get_candidates(word,vocabulary,max_dist=2)}\n",
    "            \n",
    "            \n",
    "            sentence[index] = max(candidates, key=candidates.get)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T16:03:56.433115Z",
     "start_time": "2021-04-22T16:03:56.367915Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'big', 'house']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_with_bigrams([\"the\",\"big\",\"hose\"], vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T16:04:00.671690Z",
     "start_time": "2021-04-22T16:04:00.598626Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Rose': 6.87789444724655e-05,\n",
       " 'hole': 0.0019202404016783775,\n",
       " 'home': 0.0006602778669356688,\n",
       " 'homse': 0.0,\n",
       " 'hope': 0.00012380210005043788,\n",
       " 'horse': 1.37557888944931e-05,\n",
       " 'hoses': 1.37557888944931e-05,\n",
       " 'house': 0.00660255290938049,\n",
       " 'lose': 4.12673666834793e-05,\n",
       " 'nose': 4.12673666834793e-05,\n",
       " 'rose': 6.87789444724655e-05,\n",
       " 'those': 2.75115777889862e-05}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'hose'\n",
    "previous_word = 'the'\n",
    "candidates = {candidate:interpolation_probability(previous_word, candidate, bigram_freq_dict,n_vocabulary, lambda_1=0.3) for candidate in get_candidates(word,vocabulary,max_dist=2)}\n",
    "candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-04-16T10:16:08.243Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy_bigrams(test, vocabulary):\n",
    "    # Write your code here\n",
    "    count_total_words = 0\n",
    "    count_corrected_words = 0\n",
    "    mistakes = []\n",
    "    for m,sentence in enumerate(test):\n",
    "        s_true = sentence['corrected']\n",
    "        s_hat  = correct_with_bigrams(sentence['original'].copy(), vocabulary)\n",
    "        count_total_words  += len(s_true)\n",
    "        correct_predictions = sum(s_hat[n] == s_true[n] for n in range(len(s_true)))\n",
    "        count_corrected_words += correct_predictions\n",
    "        if correct_predictions != len(s_true):\n",
    "            mistakes.append(m)\n",
    "            \n",
    "    return count_corrected_words/count_total_words, mistakes\n",
    "\n",
    "acc, mistakes = accuracy_bigrams(test, vocabulary)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-04-16T10:16:09.840Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 14\n",
    "sentence = test[mistakes[i]]\n",
    "x = sentence[\"original\"]\n",
    "y_true = sentence[\"corrected\"]\n",
    "y_hat  = correct_with_bigrams(sentence['original'].copy(), vocabulary)\n",
    "\n",
    "print(f'mistake indices = {sentence[\"indexes\"]}')\n",
    "print(f'x      = {x}')\n",
    "print(f'y_hat  = {y_hat}')\n",
    "print(f'y_true = {y_true}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-04-16T10:16:10.829Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 4\n",
    "sentence = test[mistakes[i]]\n",
    "\n",
    "x      = sentence[\"original\"]\n",
    "y_true = sentence[\"corrected\"]\n",
    "y_hat  = correct_with_bigrams(sentence['original'].copy(), vocabulary)\n",
    "\n",
    "print(f'mistakes[i]={mistakes[i]}')\n",
    "print(f'mistake indices = {sentence[\"indexes\"]}')\n",
    "print(f'x      = {x}')\n",
    "print(f'y_hat  = {y_hat}')\n",
    "print(f'y_true = {y_true}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T09:44:05.852052Z",
     "start_time": "2021-04-16T09:44:05.849102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original': ['on', 'sundays', 'I', 'go', 'to', 'church', '.'],\n",
       " 'corrected': ['on', 'sundays', 'I', 'go', 'to', 'church', '.'],\n",
       " 'indexes': []}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T09:44:06.740212Z",
     "start_time": "2021-04-16T09:44:06.637516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mistakes[i]=33\n",
      "mistake indices = [15, 26]\n",
      "x      = ['The', 'murder', 'man', 'has', 'a', 'black', 'beard', 'The', 'next', 'day', 'one', 'of', 'the', 'policemen', 'were', 'killd', 'the', 'next', 'day', 'they', 'found', 'the', 'car', 'over', 'the', 'Hill', 'the', 'was', 'the', 'man', 'near', 'it', 'he', 'was', 'dead', '.']\n",
      "y_hat  = ['The', 'murder', 'man', 'has', 'a', 'black', 'heard', 'The', 'next', 'day', 'one', 'of', 'the', 'policemen', 'were', 'killed', 'the', 'next', 'day', 'they', 'found', 'the', 'car', 'over', 'the', 'Hill', 'the', 'was', 'the', 'man', 'near', 'it', 'he', 'was', 'dead', '.']\n",
      "y_true = ['The', 'murder', 'man', 'has', 'a', 'black', 'beard', 'The', 'next', 'day', 'one', 'of', 'the', 'policemen', 'were', 'killed', 'the', 'next', 'day', 'they', 'found', 'the', 'car', 'over', 'the', 'Hill', 'there', 'was', 'the', 'man', 'near', 'it', 'he', 'was', 'dead', '.']\n"
     ]
    }
   ],
   "source": [
    "i = 20\n",
    "sentence = test[mistakes[i]]\n",
    "x      = sentence[\"original\"]\n",
    "y_true = sentence[\"corrected\"]\n",
    "y_hat  = correct_with_bigrams(sentence['original'].copy(), vocabulary)\n",
    "\n",
    "\n",
    "print(f'mistakes[i]={mistakes[i]}')\n",
    "print(f'mistake indices = {sentence[\"indexes\"]}')\n",
    "print(f'x      = {x}')\n",
    "print(f'y_hat  = {y_hat}')\n",
    "print(f'y_true = {y_true}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
